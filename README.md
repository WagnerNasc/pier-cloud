# Pier Test - MicroserviÃ§os de Processamento de Dados

[![Open in Visual Studio Code](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.com/wagnernasc/pier-cloud/pier-test)

## ğŸš© Tecnologias

![NodeJS](https://img.shields.io/badge/node.js-6DA55F?style=for-the-badge&logo=node.js&logoColor=white)
![Typescript](https://img.shields.io/badge/typescript-2f74c0?style=for-the-badge&logo=typescript&logoColor=white)
![Express](https://img.shields.io/badge/express.js-%23404d59.svg?style=for-the-badge&logo=express&logoColor=%2361DAFB)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-000?style=for-the-badge&logo=apachekafka)
![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)

## ğŸ”— DescriÃ§Ã£o

Sistema distribuÃ­do composto por dois microserviÃ§os que processam dados de vendas atravÃ©s de comunicaÃ§Ã£o assÃ­ncrona via Apache Kafka. O **Service-Job** coleta dados de vendedores da API da Pier Cloud e os envia para processamento, enquanto o **Service-Worker** consome essas mensagens e gera relatÃ³rios consolidados em formato CSV.

### Arquitetura dos ServiÃ§os

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Kafka Queue      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Service-Job   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ Service-Worker  â”‚
â”‚                 â”‚  SELLER_MESSAGE     â”‚                 â”‚
â”‚ â€¢ Busca dados   â”‚                     â”‚ â€¢ Consome msgs  â”‚
â”‚ â€¢ Envia para    â”‚                     â”‚ â€¢ Gera CSVs     â”‚
â”‚   Kafka         â”‚                     â”‚ â€¢ Processa      â”‚
â”‚                 â”‚                     â”‚   relatÃ³rios    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                        â”‚
        â–¼                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pier Cloud API â”‚                     â”‚   CSV Reports   â”‚
â”‚ â€¢ Vendedores    â”‚                     â”‚ â€¢ Vendas por    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚   vendedor      â”‚
                                        â”‚ â€¢ Dados         â”‚
                                        â”‚   consolidados  â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estrutura do Projeto

```
pier-test/
â”œâ”€â”€ docker-compose.yml          # Kafka + Zookeeper
â”œâ”€â”€ project/
â”‚   â”œâ”€â”€ service-job/           # Producer - Envia dados para Kafka
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ api/       # IntegraÃ§Ãµes com API externa
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ broker/    # Kafka Producer
â”‚   â”‚   â”‚   â”œâ”€â”€ services/      # LÃ³gica de negÃ³cio
â”‚   â”‚   â”‚   â””â”€â”€ server.ts      # Servidor principal
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â””â”€â”€ service-worker/        # Consumer - Processa dados do Kafka
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ providers/
â”‚       â”‚   â”‚   â”œâ”€â”€ api/       # IntegraÃ§Ãµes com API externa
â”‚       â”‚   â”‚   â””â”€â”€ broker/    # Kafka Consumer
â”‚       â”‚   â”œâ”€â”€ services/      # GeraÃ§Ã£o de relatÃ³rios
â”‚       â”‚   â”œâ”€â”€ routes/        # Endpoints HTTP
â”‚       â”‚   â””â”€â”€ server.ts      # Servidor principal
â”‚       â””â”€â”€ package.json
```

## ğŸš¦ Rodando o Projeto

### PrÃ©-requisitos

- Docker e Docker Compose
- Node.js v20+
- NPM v11+

### 1. Subindo a infraestrutura (Kafka)

```bash
# Na raiz do projeto
docker-compose up -d

# Verificar se os serviÃ§os estÃ£o rodando
docker-compose ps
```

### 2. Configurando variÃ¡veis de ambiente

Crie arquivos `.env` em cada serviÃ§o:

**service-job/.env:**
```env
NODE_ENV=dev
PORT=3000
EXTERNAL_API_URL=pier-cloud-api
KAFKA_BROKER=localhost:9092
```

**service-worker/.env:**
```env
NODE_ENV=dev
PORT=3001
EXTERNAL_API_URL=pier-cloud-api
KAFKA_BROKER=localhost:9092
```

### 3. Instalando dependÃªncias

```bash
# Service-Job
cd project/service-job
npm install

# Service-Worker
cd ../service-worker
npm install
```

### 4. Executando os serviÃ§os

```bash
# Terminal 1 - Service-Job (Producer)
cd project/service-job
npm run dev

# Terminal 2 - Service-Worker (Consumer)
cd project/service-worker
npm run dev
```

## ğŸ”§ Funcionalidades

### Service-Job (Producer)
- ğŸ“Š Coleta dados de vendedores da API externa
- ğŸš€ Envia mensagens em lote para o Kafka
- ğŸ“ˆ Processa dados em batches de 10 registros
- âš¡ Retry automÃ¡tico em caso de falhas

### Service-Worker (Consumer)
- ğŸ“¨ Consome mensagens do tÃ³pico `SELLER_MESSAGE`
- ğŸ“‹ Gera relatÃ³rios consolidados em CSV
- ğŸ”„ Processa vendas, produtos, clientes e vendedores

## ğŸ³ Docker

O projeto inclui configuraÃ§Ã£o completa do Kafka:

```yaml
# docker-compose.yml inclui:
- Zookeeper (porta 2181)
- Kafka (porta 9092)
- Healthchecks automÃ¡ticos
- Auto-criaÃ§Ã£o de tÃ³picos
```

## ğŸš€ Requisitos para Deploy

- Docker e Docker Compose
- Node.js v20.18.0+

## ğŸ§—ï¸ ResponsÃ¡veis

- [Wagner Nascimento](https://github.com/WagnerNasc)
