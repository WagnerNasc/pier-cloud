# Pier Test - MicroserviÃ§os de Processamento de Dados

## ğŸš© Tecnologias

![NodeJS](https://img.shields.io/badge/node.js-6DA55F?style=for-the-badge&logo=node.js&logoColor=white)
![Typescript](https://img.shields.io/badge/typescript-2f74c0?style=for-the-badge&logo=typescript&logoColor=white)
![Express](https://img.shields.io/badge/express.js-%23404d59.svg?style=for-the-badge&logo=express&logoColor=%2361DAFB)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-000?style=for-the-badge&logo=apachekafka)
![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)

## ğŸ”— DescriÃ§Ã£o

Sistema distribuÃ­do composto por dois microserviÃ§os que processam dados de vendas atravÃ©s de comunicaÃ§Ã£o assÃ­ncrona via Apache Kafka. O **Service-Job** coleta dados de vendedores da API da Pier Cloud e os envia para processamento, enquanto o **Service-Worker** consome essas mensagens e gera relatÃ³rios consolidados em formato CSV.

### Arquitetura dos ServiÃ§os

```
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚         Pier Cloud API          â”‚
                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
                   â”‚  â”‚     Endpoints DisponÃ­veis   â”‚â”‚
                   â”‚  â”‚ â€¢ GET /vendedores           â”‚â”‚
                   â”‚  â”‚ â€¢ GET /vendas               â”‚â”‚
                   â”‚  â”‚ â€¢ GET /clientes             â”‚â”‚
                   â”‚  â”‚ â€¢ GET /produtos             â”‚â”‚
                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                 â”‚
                    â–¼                                 â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚      Service-Job        â”‚  Kafka  â”‚     Service-Worker      â”‚
      â”‚      (Producer)         â”‚ â”€â”€â”€â”€â”€â”€â†’ â”‚      (Consumer)         â”‚
      â”‚                         â”‚ Message â”‚                         â”‚
      â”‚ Consome da Pier Cloud:  â”‚         â”‚ Consome da Pier Cloud:  â”‚
      â”‚  GET /vendedores        â”‚         â”‚  GET /vendas            â”‚
      â”‚                         â”‚         â”‚  GET /clientes          â”‚
      â”‚ Funcionalidades:        â”‚         â”‚  GET /produtos          â”‚
      â”‚ â€¢ Busca vendedores      â”‚         â”‚                         â”‚
      â”‚ â€¢ Processa em lotes     â”‚         â”‚ Funcionalidades:        â”‚
      â”‚ â€¢ Envia para Kafka      â”‚         â”‚ â€¢ Consome mensagens     â”‚
      â”‚   (SELLER_MESSAGE)      â”‚         â”‚ â€¢ Busca dados de vendas â”‚
      â”‚                         â”‚         â”‚ â€¢ Gera relatÃ³rios CSV   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚
                                                      â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚      CSV Reports        â”‚
                                          â”‚ â€¢ vendas_{seller}.csv   â”‚
                                          â”‚ â€¢ Dados consolidados    â”‚
                                          â”‚ â€¢ Um arquivo por seller â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## ğŸš¦ Rodando o Projeto

### PrÃ©-requisitos

- Docker e Docker Compose
- Node.js v20+
- NPM v11+

### 1. Subindo a infraestrutura (Kafka)

```bash
# Na raiz do projeto
docker-compose up -d

# Verificar se os serviÃ§os estÃ£o rodando
docker-compose ps
```

### 2. Configurando variÃ¡veis de ambiente

Crie arquivos `.env` em cada serviÃ§o (substitua o valor de EXTERNAL_API_URL pelo ):

**service-job/.env:**
```env
NODE_ENV=dev
PORT=3000
EXTERNAL_API_URL=pier-cloud-api
KAFKA_BROKER=localhost:9092
```

**service-worker/.env:**
```env
NODE_ENV=dev
PORT=3001
EXTERNAL_API_URL=pier-cloud-api
KAFKA_BROKER=localhost:9092
```

### 3. Instalando dependÃªncias

```bash
# Service-Job
cd project/service-job
npm install

# Service-Worker
cd ../service-worker
npm install
```

### 4. Executando os serviÃ§os

```bash
# Terminal 1 - Service-Job (Producer)
cd project/service-job
npm run dev

# Terminal 2 - Service-Worker (Consumer)
cd project/service-worker
npm run dev
```

## ğŸ”§ Funcionalidades

### Service-Job (Producer) ğŸ”„
**ResponsÃ¡vel por distribuir o trabalho de geraÃ§Ã£o de relatÃ³rios**

- **ğŸ¯ API Pier Cloud**: Consome apenas `GET /vendedores`
- **ğŸ“Š Processamento**: Coleta todos os vendedores e processa em lotes de 10
- **ğŸš€ Kafka**: Envia cada vendedor individualmente para `SELLER_MESSAGE`
- **âš¡ ResilÃªncia**: Retry automÃ¡tico em caso de falhas
- **ğŸ“ˆ Performance**: Processamento em batches para otimizar envio

### Service-Worker (Consumer) ğŸ“Š  
**ResponsÃ¡vel por gerar relatÃ³rios completos de vendas por vendedor**

- **ğŸ¯ API Pier Cloud**: Consome mÃºltiplas rotas:
  - `GET /vendas` - Todas as vendas (filtra por vendedor)
  - `GET /clientes/{id}` - Dados especÃ­ficos de clientes
  - `GET /produtos/{id}` - Dados especÃ­ficos de produtos
- **ğŸ“¨ Kafka**: Consome mensagens do tÃ³pico `SELLER_MESSAGE`
- **ğŸ“‹ RelatÃ³rios**: Gera CSV consolidado por vendedor
- **ğŸ”„ ConsolidaÃ§Ã£o**: Cruza dados de vendas, clientes e produtos
- **ğŸ’¾ Output**: Arquivos CSV salvos em `/reports`

## ğŸ³ Docker

O projeto inclui configuraÃ§Ã£o completa do Kafka:

```yaml
# docker-compose.yml inclui:
- Zookeeper (porta 2181)
- Kafka (porta 9092)
```

## ğŸš€ Requisitos para Deploy

- Docker e Docker Compose
- Node.js v20.18.0+

## ğŸ§—ï¸ Autores

- [Wagner Nascimento](https://github.com/WagnerNasc)
